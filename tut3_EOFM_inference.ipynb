{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Inference and Results Visualization \n",
    "\n",
    "Welcome to the **inference and visualization** part of Tutorial 3! Here you'll see your fine-tuned Clay model in action, making predictions on real satellite imagery.\n",
    "\n",
    "## What You'll Learn\n",
    "- How to load a trained segmentation model for inference\n",
    "- Techniques for visualizing model predictions\n",
    "- How to interpret land cover segmentation results\n",
    "- Methods for comparing predictions with ground truth\n",
    "- Best practices for model evaluation\n",
    "\n",
    "## What We'll Do\n",
    "1. **Load the trained model** from the previous notebook\n",
    "2. **Prepare validation data** for testing\n",
    "3. **Run inference** to generate predictions  \n",
    "4. **Visualize results** with color-coded land cover maps\n",
    "5. **Compare predictions** with ground truth labels\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "### For GIS Professionals üìç\n",
    "- **Inference**: Using your trained model to classify new imagery\n",
    "- **Visualization**: Creating interpretable land cover maps from model outputs\n",
    "- Think of this as automated feature extraction and classification\n",
    "- Results can be exported as GeoTIFF files for use in GIS software\n",
    "\n",
    "### For Data Analysts üìä\n",
    "- **Model evaluation**: Assessing how well our model performs\n",
    "- **Visual validation**: Checking predictions against known ground truth\n",
    "- **Pattern recognition**: Understanding what the model learned vs. missed\n",
    "- **Quality assessment**: Identifying areas for model improvement\n",
    "\n",
    "### For ML Engineers ü§ñ\n",
    "- **Inference pipeline**: Loading checkpoints and running forward passes\n",
    "- **Post-processing**: Converting logits to class predictions\n",
    "- **Batch processing**: Efficient handling of multiple images\n",
    "- **Model interpretation**: Understanding model behavior through visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÇ Environment Setup\n",
    "\n",
    "**Important**: This notebook assumes you've completed the training notebook first. If you haven't, please run `tut3_EOFM_finetune.ipynb` before proceeding.\n",
    "\n",
    "Let's make sure we're in the correct directory and have access to our trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5677,
     "status": "ok",
     "timestamp": 1753698661576,
     "user": {
      "displayName": "Soumya Ranjan",
      "userId": "07004583440856095975"
     },
     "user_tz": -330
    },
    "id": "FoerYdfrk115"
   },
   "outputs": [],
   "source": [
    "# Navigate to the model directory (if not already there)\n",
    "%cd model/\n",
    "\n",
    "# Verify we have the necessary files\n",
    "print(\"üìÅ Current directory contents:\")\n",
    "!ls -la\n",
    "\n",
    "print(\"\\nüîç Checking for trained model...\")\n",
    "!ls -la checkpoints/segment/lightning_logs/*/checkpoints/ 2>/dev/null || echo \"‚ùå No trained model found - please run the training notebook first!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Import Required Libraries\n",
    "\n",
    "Let's import all the tools we need for inference and visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7774,
     "status": "ok",
     "timestamp": 1753704792942,
     "user": {
      "displayName": "Soumya Ranjan",
      "userId": "07004583440856095975"
     },
     "user_tz": -330
    },
    "id": "79cQtuG8zjHJ"
   },
   "outputs": [],
   "source": [
    "# Core Python libraries\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# PyTorch for deep learning\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Additional utilities  \n",
    "from einops import rearrange\n",
    "\n",
    "# Add claymodel to path and import our custom modules\n",
    "sys.path.append(\"./claymodel\")\n",
    "from claymodel.finetune.segment.chesapeake_datamodule import ChesapeakeDataModule\n",
    "from claymodel.finetune.segment.chesapeake_model import ChesapeakeSegmentor\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"üîß PyTorch version: {torch.__version__}\")\n",
    "print(f\"üéÆ GPU available: {'Yes' if torch.cuda.is_available() else 'No (using CPU)'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configuration and File Paths\n",
    "\n",
    "Let's define all the paths and parameters we'll need. These should match what you used in the training notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1753705499470,
     "user": {
      "displayName": "Soumya Ranjan",
      "userId": "07004583440856095975"
     },
     "user_tz": -330
    },
    "id": "MzaVKezS7myo"
   },
   "outputs": [],
   "source": [
    "# File paths and configuration\n",
    "CHESAPEAKE_CHECKPOINT_PATH = \"checkpoints/segment/lightning_logs/version_0/checkpoints/epoch=0-step=63.ckpt\"\n",
    "CLAY_CHECKPOINT_PATH = \"checkpoints/clay-v1.5.ckpt\"\n",
    "METADATA_PATH = \"configs/metadata.yaml\"\n",
    "\n",
    "# Data directories\n",
    "TRAIN_CHIP_DIR = \"data/cvpr/ny/train/chips/\"\n",
    "TRAIN_LABEL_DIR = \"data/cvpr/ny/train/labels/\"\n",
    "VAL_CHIP_DIR = \"data/cvpr/ny/val/chips/\"\n",
    "VAL_LABEL_DIR = \"data/cvpr/ny/val/labels/\"\n",
    "\n",
    "# Data loading parameters\n",
    "BATCH_SIZE = 32          # Process 32 images at once (larger batch for inference)\n",
    "NUM_WORKERS = 1          # Single worker to avoid issues in Colab\n",
    "PLATFORM = \"naip\"        # NAIP aerial imagery platform\n",
    "\n",
    "print(\"üìã Configuration loaded:\")\n",
    "print(f\"   üéØ Model checkpoint: {CHESAPEAKE_CHECKPOINT_PATH}\")\n",
    "print(f\"   üß† Clay model: {CLAY_CHECKPOINT_PATH}\")\n",
    "print(f\"   üìä Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   üì∑ Platform: {PLATFORM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Helper Functions\n",
    "\n",
    "Let's define functions to handle model loading, data preparation, inference, and visualization. Breaking these into functions makes the code more organized and reusable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1753704799919,
     "user": {
      "displayName": "Soumya Ranjan",
      "userId": "07004583440856095975"
     },
     "user_tz": -330
    },
    "id": "Z6bn-IR877Cd"
   },
   "outputs": [],
   "source": [
    "def get_model(chesapeake_checkpoint_path, clay_checkpoint_path, metadata_path):\n",
    "    \"\"\"\n",
    "    Load the trained segmentation model from checkpoint.\n",
    "    \n",
    "    Args:\n",
    "        chesapeake_checkpoint_path: Path to our trained model\n",
    "        clay_checkpoint_path: Path to the Clay foundation model  \n",
    "        metadata_path: Path to data normalization metadata\n",
    "        \n",
    "    Returns:\n",
    "        model: Loaded model in evaluation mode\n",
    "    \"\"\"\n",
    "    print(\"ü§ñ Loading trained model...\")\n",
    "    \n",
    "    model = ChesapeakeSegmentor.load_from_checkpoint(\n",
    "        checkpoint_path=chesapeake_checkpoint_path,\n",
    "        metadata_path=metadata_path,\n",
    "        ckpt_path=clay_checkpoint_path,\n",
    "    )\n",
    "    \n",
    "    # Set to evaluation mode (disables dropout, batch norm training mode, etc.)\n",
    "    model.eval()\n",
    "    \n",
    "    print(\"‚úÖ Model loaded successfully!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1753704800371,
     "user": {
      "displayName": "Soumya Ranjan",
      "userId": "07004583440856095975"
     },
     "user_tz": -330
    },
    "id": "zuRqtBkW8Byf"
   },
   "outputs": [],
   "source": [
    "def get_data(train_chip_dir, train_label_dir, val_chip_dir, val_label_dir, \n",
    "             metadata_path, batch_size, num_workers, platform):\n",
    "    \"\"\"\n",
    "    Set up data loading for inference.\n",
    "    \n",
    "    Args:\n",
    "        Various paths and parameters for data loading\n",
    "        \n",
    "    Returns:\n",
    "        batch: A batch of validation data\n",
    "        metadata: Data normalization and class information\n",
    "    \"\"\"\n",
    "    print(\"üìä Setting up data loader...\")\n",
    "    \n",
    "    # Create data module (same as training, but we only need validation data)\n",
    "    dm = ChesapeakeDataModule(\n",
    "        train_chip_dir=train_chip_dir,\n",
    "        train_label_dir=train_label_dir,  \n",
    "        val_chip_dir=val_chip_dir,\n",
    "        val_label_dir=val_label_dir,\n",
    "        metadata_path=metadata_path,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        platform=platform,\n",
    "    )\n",
    "    \n",
    "    # Setup the data module\n",
    "    dm.setup(stage=\"fit\")\n",
    "    \n",
    "    # Get one batch of validation data for visualization\n",
    "    val_dl = iter(dm.val_dataloader())\n",
    "    batch = next(val_dl)\n",
    "    \n",
    "    print(f\"‚úÖ Data loaded - batch contains {batch['pixels'].shape[0]} images\")\n",
    "    print(f\"üìè Image shape: {list(batch['pixels'].shape[1:])}\")\n",
    "    \n",
    "    return batch, dm.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1753704800929,
     "user": {
      "displayName": "Soumya Ranjan",
      "userId": "07004583440856095975"
     },
     "user_tz": -330
    },
    "id": "fNRlWKy18Fg6"
   },
   "outputs": [],
   "source": [
    "def run_prediction(model, batch):\n",
    "    \"\"\"\n",
    "    Run inference on a batch of images.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained segmentation model\n",
    "        batch: Batch of input images\n",
    "        \n",
    "    Returns:\n",
    "        outputs: Model predictions (probabilities for each class)\n",
    "    \"\"\"\n",
    "    print(\"üîÆ Running inference...\")\n",
    "    \n",
    "    # Disable gradient computation for faster inference\n",
    "    with torch.no_grad():\n",
    "        # Forward pass through the model\n",
    "        outputs = model(batch)\n",
    "    \n",
    "    # Upsample predictions to match original image size (256x256)\n",
    "    # The model outputs smaller feature maps that need to be upsampled\n",
    "    outputs = F.interpolate(\n",
    "        outputs, \n",
    "        size=(256, 256),           # Target size\n",
    "        mode=\"bilinear\",           # Smooth interpolation\n",
    "        align_corners=False        # PyTorch default\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Inference complete - predictions shape: {list(outputs.shape)}\")\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1753704801906,
     "user": {
      "displayName": "Soumya Ranjan",
      "userId": "07004583440856095975"
     },
     "user_tz": -330
    },
    "id": "QHb7oR7T8IhK"
   },
   "outputs": [],
   "source": [
    "def denormalize_images(normalized_images, means, stds):\n",
    "    \"\"\"\n",
    "    Convert normalized images back to viewable format.\n",
    "    \n",
    "    During training, images are normalized (mean=0, std=1) for better model performance.  \n",
    "    For visualization, we need to reverse this normalization.\n",
    "    \n",
    "    Args:\n",
    "        normalized_images: Normalized image tensors\n",
    "        means: Mean values used for normalization\n",
    "        stds: Standard deviation values used for normalization\n",
    "        \n",
    "    Returns:\n",
    "        denormalized_images: Images in 0-255 range for display\n",
    "    \"\"\"\n",
    "    means = np.array(means).reshape(1, -1, 1, 1)\n",
    "    stds = np.array(stds).reshape(1, -1, 1, 1)\n",
    "    \n",
    "    # Reverse normalization: multiply by std, then add mean\n",
    "    denormalized_images = normalized_images * stds + means\n",
    "    \n",
    "    # Convert to 0-255 range for display\n",
    "    return denormalized_images.astype(np.uint8)\n",
    "\n",
    "\n",
    "def post_process(batch, outputs, metadata):\n",
    "    \"\"\"\n",
    "    Convert model outputs and inputs into visualization-ready format.\n",
    "    \n",
    "    Args:\n",
    "        batch: Original batch of data\n",
    "        outputs: Model prediction probabilities\n",
    "        metadata: Data normalization info\n",
    "        \n",
    "    Returns:\n",
    "        images: RGB images ready for display\n",
    "        labels: Ground truth segmentation maps\n",
    "        preds: Predicted segmentation maps\n",
    "    \"\"\"\n",
    "    print(\"üîÑ Post-processing results...\")\n",
    "    \n",
    "    # Convert prediction probabilities to class predictions\n",
    "    # argmax selects the class with highest probability for each pixel\n",
    "    preds = torch.argmax(outputs, dim=1).detach().cpu().numpy()\n",
    "    \n",
    "    # Extract ground truth labels\n",
    "    labels = batch[\"label\"].detach().cpu().numpy()\n",
    "    \n",
    "    # Extract normalized pixel values\n",
    "    pixels = batch[\"pixels\"].detach().cpu().numpy()\n",
    "    \n",
    "    # Get normalization parameters for this platform (NAIP)\n",
    "    means = list(metadata[\"naip\"].bands.mean.values())\n",
    "    stds = list(metadata[\"naip\"].bands.std.values())\n",
    "    \n",
    "    # Denormalize images for display\n",
    "    norm_pixels = denormalize_images(pixels, means, stds)\n",
    "    \n",
    "    # Rearrange from (batch, channels, height, width) to (batch, height, width, channels)\n",
    "    # This is the format matplotlib expects for RGB images\n",
    "    images = rearrange(norm_pixels[:, :3, :, :], \"b c h w -> b h w c\")\n",
    "    \n",
    "    print(f\"‚úÖ Post-processing complete\")\n",
    "    print(f\"üìä Processed {len(images)} images\")\n",
    "    \n",
    "    return images, labels, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1753705487159,
     "user": {
      "displayName": "Soumya Ranjan",
      "userId": "07004583440856095975"
     },
     "user_tz": -330
    },
    "id": "uUnqSEQ48LpA"
   },
   "outputs": [],
   "source": [
    "def plot_predictions(images, labels, preds):\n",
    "    \"\"\"\n",
    "    Create a comprehensive visualization of results.\n",
    "    \n",
    "    Shows original images, ground truth labels, and model predictions\n",
    "    in an easy-to-compare grid format.\n",
    "    \n",
    "    Args:\n",
    "        images: RGB aerial images\n",
    "        labels: Ground truth segmentation maps  \n",
    "        preds: Model predicted segmentation maps\n",
    "    \"\"\"\n",
    "    print(\"üé® Creating visualization...\")\n",
    "    \n",
    "    # Define colors for each land cover class\n",
    "    # These colors are chosen to be intuitive and visually distinct\n",
    "    colors = [\n",
    "        (0/255, 0/255, 255/255, 1),         # Deep Blue for water üíß\n",
    "        (34/255, 139/255, 34/255, 1),       # Forest Green for tree canopy üå≥\n",
    "        (154/255, 205/255, 50/255, 1),      # Yellow Green for low vegetation üå±\n",
    "        (210/255, 180/255, 140/255, 1),     # Tan for barren land üèîÔ∏è\n",
    "        (169/255, 169/255, 169/255, 1),     # Dark Gray for impervious (other) üè¢\n",
    "        (105/255, 105/255, 105/255, 1),     # Dim Gray for impervious (road) üõ£Ô∏è\n",
    "        (255/255, 255/255, 255/255, 1),     # White for no data ‚¨ú\n",
    "    ]\n",
    "    cmap = ListedColormap(colors)\n",
    "    \n",
    "    # Create a large figure to show all comparisons\n",
    "    fig, axes = plt.subplots(12, 8, figsize=(16, 24))\n",
    "    fig.suptitle('üåç Land Cover Segmentation Results', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Plot in three rows: Images, Ground Truth, Predictions\n",
    "    plot_data(axes, images, row_offset=0, title=\"üì∑ Original Image\")\n",
    "    plot_data(axes, labels, row_offset=1, title=\"üéØ Ground Truth\", cmap=cmap, vmin=0, vmax=6)\n",
    "    plot_data(axes, preds, row_offset=2, title=\"ü§ñ Model Prediction\", cmap=cmap, vmin=0, vmax=6)\n",
    "    \n",
    "    # Add a legend explaining the color scheme\n",
    "    add_legend(fig, cmap)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Visualization complete!\")\n",
    "\n",
    "\n",
    "def plot_data(axes, data, row_offset, title=None, cmap=None, vmin=None, vmax=None):\n",
    "    \"\"\"Helper function to plot a row of data in the grid.\"\"\"\n",
    "    for i, item in enumerate(data):\n",
    "        if i >= 24:  # Only show first 24 images (3 rows of 8)\n",
    "            break\n",
    "            \n",
    "        row = row_offset + (i // 8) * 3\n",
    "        col = i % 8\n",
    "        \n",
    "        axes[row, col].imshow(item, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "        axes[row, col].axis(\"off\")\n",
    "        \n",
    "        # Add row titles\n",
    "        if title and col == 0:\n",
    "            axes[row, col].set_ylabel(title, rotation=0, fontsize=12, \n",
    "                                    fontweight='bold', ha='right', va='center')\n",
    "\n",
    "\n",
    "def add_legend(fig, cmap):\n",
    "    \"\"\"Add a color legend explaining the land cover classes.\"\"\"\n",
    "    class_names = [\n",
    "        \"üíß Water\",\n",
    "        \"üå≥ Tree Canopy\", \n",
    "        \"üå± Low Vegetation\",\n",
    "        \"üèîÔ∏è Barren Land\",\n",
    "        \"üè¢ Impervious (Other)\",\n",
    "        \"üõ£Ô∏è Impervious (Roads)\", \n",
    "        \"‚¨ú No Data\"\n",
    "    ]\n",
    "    \n",
    "    # Create legend patches\n",
    "    import matplotlib.patches as mpatches\n",
    "    patches = [mpatches.Patch(color=cmap.colors[i], label=class_names[i]) \n",
    "               for i in range(len(class_names))]\n",
    "    \n",
    "    # Add legend to the figure\n",
    "    fig.legend(handles=patches, loc='center', bbox_to_anchor=(0.5, 0.02), \n",
    "               ncol=4, fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Run the Complete Inference Pipeline\n",
    "\n",
    "Now let's put it all together! We'll load the model, prepare data, run inference, and visualize results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 37596,
     "status": "ok",
     "timestamp": 1753705388920,
     "user": {
      "displayName": "Soumya Ranjan",
      "userId": "07004583440856095975"
     },
     "user_tz": -330
    },
    "id": "59ulQ_6_8O9p"
   },
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model = get_model(CHESAPEAKE_CHECKPOINT_PATH, CLAY_CHECKPOINT_PATH, METADATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 919,
     "status": "ok",
     "timestamp": 1753705512246,
     "user": {
      "displayName": "Soumya Ranjan",
      "userId": "07004583440856095975"
     },
     "user_tz": -330
    },
    "id": "ENe89qFL8RNl"
   },
   "outputs": [],
   "source": [
    "# Get validation data for testing\n",
    "batch, metadata = get_data(\n",
    "    TRAIN_CHIP_DIR,\n",
    "    TRAIN_LABEL_DIR,\n",
    "    VAL_CHIP_DIR,\n",
    "    VAL_LABEL_DIR,\n",
    "    METADATA_PATH,\n",
    "    BATCH_SIZE,\n",
    "    NUM_WORKERS,\n",
    "    PLATFORM,\n",
    ")\n",
    "\n",
    "# Move data to GPU if available (same device as model)\n",
    "device = next(model.parameters()).device\n",
    "batch = {k: v.to(device) for k, v in batch.items()}\n",
    "print(f\"üì± Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4997,
     "status": "ok",
     "timestamp": 1753705518228,
     "user": {
      "displayName": "Soumya Ranjan",
      "userId": "07004583440856095975"
     },
     "user_tz": -330
    },
    "id": "EDNX9uql8Z0O"
   },
   "outputs": [],
   "source": [
    "# Run inference on the batch\n",
    "outputs = run_prediction(model, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 63,
     "status": "ok",
     "timestamp": 1753705519735,
     "user": {
      "displayName": "Soumya Ranjan",
      "userId": "07004583440856095975"
     },
     "user_tz": -330
    },
    "id": "8yxPaSul8cUK"
   },
   "outputs": [],
   "source": [
    "# Post-process results for visualization\n",
    "images, labels, preds = post_process(batch, outputs, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2918,
     "status": "ok",
     "timestamp": 1753705523671,
     "user": {
      "displayName": "Soumya Ranjan",
      "userId": "07004583440856095975"
     },
     "user_tz": -330
    },
    "id": "SLig0yiy_P4I",
    "outputId": "a5776d39-83a6-408f-a179-1f0f68f3d236"
   },
   "outputs": [],
   "source": [
    "# Create the final visualization\n",
    "plot_predictions(images, labels, preds)\n",
    "\n",
    "print(\"\\nüéâ Inference and visualization complete!\")\n",
    "print(\"\\nüîç What to Look For:\")\n",
    "print(\"   ‚Ä¢ How well does the model identify water bodies?\")\n",
    "print(\"   ‚Ä¢ Are forest areas correctly classified?\") \n",
    "print(\"   ‚Ä¢ Does the model distinguish between different types of impervious surfaces?\")\n",
    "print(\"   ‚Ä¢ Where does the model struggle or make mistakes?\")\n",
    "print(\"\\nüí° Next Steps:\")\n",
    "print(\"   ‚Ä¢ Try running on more batches to see consistency\")\n",
    "print(\"   ‚Ä¢ Consider additional training epochs for better performance\")\n",
    "print(\"   ‚Ä¢ Experiment with different learning rates or data augmentation\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNR7shfz8QYTJ76+LqkLSft",
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01f991cfee5b45b6845dd1ed546f2b0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "055bcb3145934ce981516b35303bc652": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a5819e92f85b47bcb430695fdffa0d7e",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_01f991cfee5b45b6845dd1ed546f2b0e",
      "value": "‚Äá63/63‚Äá[04:27&lt;00:00,‚Äá‚Äá0.24it/s]"
     }
    },
    "1ccb42bc6c364b7392dd6cd198ee9766": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e8954b000b3a423baf6f57b6d66c8ce4",
      "max": 63,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e96da0097d8a4bc4b5baa46c6b627021",
      "value": 63
     }
    },
    "1e9fb43410a5494c9bb23556bc2e3b44": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": "100%"
     }
    },
    "2606f336d9ce487e97b464a7ca5667b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "2f2be8a1fa1848a9bf0d1a12036d17c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "308313ec25864ba9a62d5e7b53018505": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d65c7174c746426099a583e6df40a7f4",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_979b681021794c67a275a8e24e466282",
      "value": "Epoch‚Äá1:‚Äá‚Äá32%"
     }
    },
    "31d8003099ba485c9786493013210155": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_edd0a95d995c4282a7dbb4455eb69e6c",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_93886706e3e44f37afef57c6a360348a",
      "value": "‚Äá20/63‚Äá[01:40&lt;03:36,‚Äá‚Äá0.20it/s,‚Äáv_num=0,‚Äátrain/loss_step=0.203,‚Äátrain/iou_step=0.752,‚Äátrain/f1_step=0.845,‚Äával/loss_step=0.0938,‚Äával/iou_step=0.901,‚Äával/f1_step=0.947,‚Äával/loss_epoch=0.158,‚Äával/iou_epoch=0.831,‚Äával/f1_epoch=0.897,‚Äátrain/loss_epoch=0.340,‚Äátrain/iou_epoch=0.726,‚Äátrain/f1_epoch=0.811]"
     }
    },
    "447f1e98679644ce8a0ba5d049653234": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_980083c34e924210b439d8e5f670293b",
       "IPY_MODEL_1ccb42bc6c364b7392dd6cd198ee9766",
       "IPY_MODEL_055bcb3145934ce981516b35303bc652"
      ],
      "layout": "IPY_MODEL_1e9fb43410a5494c9bb23556bc2e3b44"
     }
    },
    "643c6f27f9f34745a1875c628a128d77": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7aa597bc97674e2499d1325d584badb4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_308313ec25864ba9a62d5e7b53018505",
       "IPY_MODEL_d59c964b0d7940318fbeacb7448e7cc6",
       "IPY_MODEL_31d8003099ba485c9786493013210155"
      ],
      "layout": "IPY_MODEL_2606f336d9ce487e97b464a7ca5667b9"
     }
    },
    "8e2bdc0ac29a466ab540235ecd1b9466": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "93886706e3e44f37afef57c6a360348a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "979b681021794c67a275a8e24e466282": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "980083c34e924210b439d8e5f670293b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de6ab9352f3f435abe7449189db82787",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_2f2be8a1fa1848a9bf0d1a12036d17c7",
      "value": "Validation‚ÄáDataLoader‚Äá0:‚Äá100%"
     }
    },
    "a5819e92f85b47bcb430695fdffa0d7e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d59c964b0d7940318fbeacb7448e7cc6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_643c6f27f9f34745a1875c628a128d77",
      "max": 63,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8e2bdc0ac29a466ab540235ecd1b9466",
      "value": 20
     }
    },
    "d65c7174c746426099a583e6df40a7f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de6ab9352f3f435abe7449189db82787": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e8954b000b3a423baf6f57b6d66c8ce4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e96da0097d8a4bc4b5baa46c6b627021": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "edd0a95d995c4282a7dbb4455eb69e6c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
